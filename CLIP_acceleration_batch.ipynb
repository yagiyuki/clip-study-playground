{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yagiyuki/clip-study-playground/blob/main/CLIP_acceleration_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIPで大量に画像分類するときのバッチ処理による高速化実装\n"
      ],
      "metadata": {
        "id": "8nlJuzTc6fmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1hv216fAWq5O",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# 画像を管理するパスを作成\n",
        "mkdir -p data\n",
        "\n",
        "# dataディレクトリにsample.jpegと言う名前で画像ファイルを上げる"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 画像を999枚複製（合計1000枚）\n",
        "for i in {1..1000}; do\n",
        "  cp data/sample.jpeg data/sample_${i}.jpeg\n",
        "done"
      ],
      "metadata": {
        "id": "9UPSMq_0XgPh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoImageProcessor, AutoModel, AutoTokenizer\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "HF_MODEL_PATH = 'line-corporation/clip-japanese-base'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_PATH, trust_remote_code=True)\n",
        "processor = AutoImageProcessor.from_pretrained(HF_MODEL_PATH, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(HF_MODEL_PATH, trust_remote_code=True).to(device)"
      ],
      "metadata": {
        "id": "ZkhJtqOhujlk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ベースライン"
      ],
      "metadata": {
        "id": "qfLTgBHX6t-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 単純な推論ループ\n",
        "with torch.no_grad():\n",
        "    text = tokenizer([\"ベンチプレス\", \"スクワット\", \"デッドリフト\"]).to(device)\n",
        "    text_feats = model.get_text_features(**text)\n",
        "    for path in glob.glob('data/*'):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        inputs = processor(images=[img], return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # テキスト特徴量を計算\n",
        "        img_feats  = model.get_image_features(inputs.pixel_values)\n",
        "        probs = (img_feats @ text_feats.T).softmax(dim=-1)\n",
        "        # …結果処理…\n",
        "        #print(path, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is7rMLBS6SUE",
        "outputId": "87491036-17cf-466c-f173-5c5a5f15ac70"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30.3 s, sys: 128 ms, total: 30.4 s\n",
            "Wall time: 30.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 実装 1 – 手動スライス"
      ],
      "metadata": {
        "id": "hzPiubgz_3vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "with torch.no_grad():\n",
        "    text = tokenizer([\"ベンチプレス\", \"スクワット\", \"デッドリフト\"]).to(device)\n",
        "    text_feats = model.get_text_features(**text)\n",
        "\n",
        "    image_paths = glob.glob('data/*')\n",
        "    for i in range(0, len(image_paths), batch_size):\n",
        "        # ここだけが追加：複数画像を一度に処理\n",
        "        batch = image_paths[i:i+batch_size]\n",
        "        imgs = [Image.open(p).convert(\"RGB\") for p in batch]\n",
        "        inputs = processor(images=imgs, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        img_feats = model.get_image_features(inputs.pixel_values)\n",
        "\n",
        "        probs = (img_feats @ text_feats.T).softmax(dim=-1)\n",
        "        # …結果処理…\n",
        "        #for path, p in zip(batch, probs):\n",
        "        #    print(path, p)"
      ],
      "metadata": {
        "id": "GrYnjbdFARkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af2129a-0b22-49e4-a1cc-d65db97a5296"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.9 s, sys: 271 ms, total: 17.2 s\n",
            "Wall time: 17.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 実装 2 – DataLoader にパスを直渡"
      ],
      "metadata": {
        "id": "nKqkpPGL6zm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 画像パス一覧\n",
        "image_paths = glob.glob('data/*')\n",
        "\n",
        "# DataLoader で自動的に path のリストをバッチ化\n",
        "dataloader = DataLoader(\n",
        "    image_paths,\n",
        "    batch_size=50,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_paths in dataloader:\n",
        "        # batch_paths は文字列のリスト\n",
        "        imgs = [Image.open(p).convert(\"RGB\") for p in batch_paths]\n",
        "        inputs = processor(images=imgs, return_tensors=\"pt\").to(device)\n",
        "        img_feats = model.get_image_features(inputs.pixel_values)\n",
        "        probs = (img_feats @ text_feats.T).softmax(dim=-1)\n",
        "        # …結果処理…\n",
        "        #for path, p in zip(batch_paths, probs):\n",
        "        #    print(path, p)"
      ],
      "metadata": {
        "id": "WxGeHRVSWxrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a5a161-f6e8-412d-bf3c-41ba89ae8e73"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.5 s, sys: 69.6 ms, total: 17.5 s\n",
            "Wall time: 17.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "free -h\n",
        "\n"
      ],
      "metadata": {
        "id": "U010C3AZLhvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d8cc26-d343-4f15-e3cd-7b29ae278d55"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       2.9Gi       2.2Gi        16Mi       7.6Gi       9.5Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6LdTgCbLiqT"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}